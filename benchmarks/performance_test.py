#!/usr/bin/env python3
"""
AquaVM æ€§èƒ½åŸºå‡†æµ‹è¯•

æ¯”è¾ƒä¸åŒç‰ˆæœ¬è™šæ‹Ÿæœºçš„æ€§èƒ½ï¼š
1. åŽŸå§‹Pythonç‰ˆæœ¬
2. ä¼˜åŒ–Pythonç‰ˆæœ¬
3. Cythonç‰ˆæœ¬
4. Rustç‰ˆæœ¬ï¼ˆé€šè¿‡Pythonç»‘å®šï¼‰
"""

import time
import sys
import os
import subprocess
import statistics
from typing import List, Dict, Any

# æ·»åŠ VMè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'vm'))

class BenchmarkSuite:
    """æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = {}
        self.test_files = [
            'test_simple_vm.acode',
            'test_string.acode',
            'test_global.acode',
        ]
    
    def run_benchmark(self, vm_name: str, vm_runner: callable, iterations: int = 10) -> Dict[str, Any]:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        print(f"\n=== æµ‹è¯• {vm_name} ===")
        
        results = {
            'vm_name': vm_name,
            'iterations': iterations,
            'tests': {}
        }
        
        for test_file in self.test_files:
            if not os.path.exists(test_file):
                print(f"è·³è¿‡ {test_file} (æ–‡ä»¶ä¸å­˜åœ¨)")
                continue
            
            print(f"æµ‹è¯• {test_file}...")
            times = []
            
            for i in range(iterations):
                try:
                    start_time = time.perf_counter()
                    vm_runner(test_file)
                    end_time = time.perf_counter()
                    
                    execution_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                    times.append(execution_time)
                    
                except Exception as e:
                    print(f"  é”™è¯¯ (ç¬¬{i+1}æ¬¡): {e}")
                    continue
            
            if times:
                results['tests'][test_file] = {
                    'times': times,
                    'avg': statistics.mean(times),
                    'min': min(times),
                    'max': max(times),
                    'std': statistics.stdev(times) if len(times) > 1 else 0,
                }
                
                print(f"  å¹³å‡: {results['tests'][test_file]['avg']:.2f}ms")
                print(f"  æœ€å°: {results['tests'][test_file]['min']:.2f}ms")
                print(f"  æœ€å¤§: {results['tests'][test_file]['max']:.2f}ms")
                print(f"  æ ‡å‡†å·®: {results['tests'][test_file]['std']:.2f}ms")
        
        return results
    
    def run_original_vm(self, test_file: str):
        """è¿è¡ŒåŽŸå§‹Pythonè™šæ‹Ÿæœº"""
        try:
            from aquavm import AquaVM
            
            vm = AquaVM()
            with open(test_file, 'rb') as f:
                bytecode = f.read()
            vm.load_bytecode(bytecode)
            
            # é‡å®šå‘è¾“å‡ºé¿å…å½±å“æ€§èƒ½æµ‹è¯•
            import io
            import contextlib
            
            f = io.StringIO()
            with contextlib.redirect_stdout(f):
                vm.run()
            
        except ImportError:
            raise Exception("åŽŸå§‹AquaVMä¸å¯ç”¨")
    
    def run_optimized_vm(self, test_file: str):
        """è¿è¡Œä¼˜åŒ–Pythonè™šæ‹Ÿæœº"""
        try:
            from optimized_aquavm import OptimizedAquaVM
            
            vm = OptimizedAquaVM()
            with open(test_file, 'rb') as f:
                bytecode = f.read()
            vm.load_bytecode(bytecode)
            
            import io
            import contextlib
            
            f = io.StringIO()
            with contextlib.redirect_stdout(f):
                vm.run()
            
        except ImportError:
            raise Exception("ä¼˜åŒ–AquaVMä¸å¯ç”¨")
    
    def run_cython_vm(self, test_file: str):
        """è¿è¡ŒCythonè™šæ‹Ÿæœº"""
        try:
            from cython_aquavm import CythonAquaVM
            
            vm = CythonAquaVM()
            with open(test_file, 'rb') as f:
                bytecode = f.read()
            vm.load_bytecode(bytecode)
            
            import io
            import contextlib
            
            f = io.StringIO()
            with contextlib.redirect_stdout(f):
                vm.run()
            
        except ImportError:
            raise Exception("Cython AquaVMä¸å¯ç”¨ (éœ€è¦ç¼–è¯‘)")
    
    def run_rust_vm(self, test_file: str):
        """è¿è¡ŒRustè™šæ‹Ÿæœº"""
        try:
            # é€šè¿‡å‘½ä»¤è¡Œè°ƒç”¨Rustè™šæ‹Ÿæœº
            result = subprocess.run(
                ['cargo', 'run', '--release', '--', test_file],
                cwd='rust_vm',
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode != 0:
                raise Exception(f"Rust VMé”™è¯¯: {result.stderr}")
            
        except FileNotFoundError:
            raise Exception("Rust VMä¸å¯ç”¨ (éœ€è¦å®‰è£…Cargo)")
        except subprocess.TimeoutExpired:
            raise Exception("Rust VMè¶…æ—¶")
    
    def run_all_benchmarks(self):
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        print("AquaVM æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 50)
        
        # æµ‹è¯•åŽŸå§‹VM
        try:
            results = self.run_benchmark("åŽŸå§‹Python VM", self.run_original_vm)
            self.results['original'] = results
        except Exception as e:
            print(f"åŽŸå§‹VMæµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•ä¼˜åŒ–VM
        try:
            results = self.run_benchmark("ä¼˜åŒ–Python VM", self.run_optimized_vm)
            self.results['optimized'] = results
        except Exception as e:
            print(f"ä¼˜åŒ–VMæµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•Cython VM
        try:
            results = self.run_benchmark("Cython VM", self.run_cython_vm)
            self.results['cython'] = results
        except Exception as e:
            print(f"Cython VMæµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•Rust VM
        try:
            results = self.run_benchmark("Rust VM", self.run_rust_vm)
            self.results['rust'] = results
        except Exception as e:
            print(f"Rust VMæµ‹è¯•å¤±è´¥: {e}")
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_comparison_report()
    
    def generate_comparison_report(self):
        """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
        print("=" * 60)
        
        if not self.results:
            print("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç»“æžœ")
            return
        
        # èŽ·å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        all_tests = set()
        for result in self.results.values():
            all_tests.update(result.get('tests', {}).keys())
        
        for test_file in sorted(all_tests):
            print(f"\nðŸ“Š {test_file}")
            print("-" * 40)
            
            baseline_time = None
            vm_times = []
            
            for vm_name, result in self.results.items():
                if test_file in result.get('tests', {}):
                    avg_time = result['tests'][test_file]['avg']
                    vm_times.append((vm_name, avg_time))
                    
                    if vm_name == 'original':
                        baseline_time = avg_time
            
            # æŒ‰æ€§èƒ½æŽ’åº
            vm_times.sort(key=lambda x: x[1])
            
            for i, (vm_name, avg_time) in enumerate(vm_times):
                speedup = ""
                if baseline_time and baseline_time > 0:
                    ratio = baseline_time / avg_time
                    if ratio > 1:
                        speedup = f" (ðŸš€ {ratio:.1f}x æ›´å¿«)"
                    elif ratio < 1:
                        speedup = f" (ðŸŒ {1/ratio:.1f}x æ›´æ…¢)"
                
                rank_emoji = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰"][i] if i < 3 else "ðŸ“"
                print(f"  {rank_emoji} {vm_name:15s}: {avg_time:8.2f}ms{speedup}")
        
        # æ€»ä½“æ€§èƒ½æŽ’å
        print(f"\nðŸ† æ€»ä½“æ€§èƒ½æŽ’å")
        print("-" * 40)
        
        vm_avg_times = {}
        for vm_name, result in self.results.items():
            times = []
            for test_data in result.get('tests', {}).values():
                times.append(test_data['avg'])
            
            if times:
                vm_avg_times[vm_name] = statistics.mean(times)
        
        sorted_vms = sorted(vm_avg_times.items(), key=lambda x: x[1])
        
        for i, (vm_name, avg_time) in enumerate(sorted_vms):
            rank_emoji = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰"][i] if i < 3 else "ðŸ“"
            print(f"  {rank_emoji} {vm_name:15s}: {avg_time:8.2f}ms (å¹³å‡)")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    benchmark = BenchmarkSuite()
    benchmark.run_all_benchmarks()

if __name__ == "__main__":
    main()